{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a864e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATASET VALIDATION RESULTS ===\n",
      "✅ No missing image files.\n",
      "✅ All transcriptions are valid (not empty).\n",
      "✅ No corrupted or unreadable images.\n",
      "\n",
      "✅ Validation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = \"data/ground_truth_lines.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "missing_files = []\n",
    "empty_images = []\n",
    "empty_text = []\n",
    "corrupted_images = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    image_path = str(row['image_path']).strip()\n",
    "    transcription = str(row['transcription']).strip()\n",
    "\n",
    "    # 1. Check if the file exists\n",
    "    if not os.path.isfile(image_path):\n",
    "        missing_files.append(image_path)\n",
    "        continue\n",
    "\n",
    "    # 2. Check transcription is not empty/null\n",
    "    if transcription == \"\" or transcription.lower() == \"nan\":\n",
    "        empty_text.append(image_path)\n",
    "\n",
    "    # 3. Check if image can be opened (not null/corrupted)\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img.verify()   # verify doesn't load full image, just checks integrity\n",
    "    except Exception:\n",
    "        corrupted_images.append(image_path)\n",
    "\n",
    "print(\"\\n=== DATASET VALIDATION RESULTS ===\")\n",
    "\n",
    "if not missing_files:\n",
    "    print(\"✅ No missing image files.\")\n",
    "else:\n",
    "    print(\"❌ Missing files:\")\n",
    "    for f in missing_files:\n",
    "        print(\"   -\", f)\n",
    "\n",
    "if not empty_text:\n",
    "    print(\"✅ All transcriptions are valid (not empty).\")\n",
    "else:\n",
    "    print(\"❌ Empty transcription entries:\")\n",
    "    for f in empty_text:\n",
    "        print(\"   -\", f)\n",
    "\n",
    "if not corrupted_images:\n",
    "    print(\"✅ No corrupted or unreadable images.\")\n",
    "else:\n",
    "    print(\"❌ Corrupted/unreadable images:\")\n",
    "    for f in corrupted_images:\n",
    "        print(\"   -\", f)\n",
    "\n",
    "print(\"\\n✅ Validation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47afb0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: python create_lmdb_nested_csv.py <output_lmdb_path> <image_root_folder> <truth.csv>\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shay\\ocrenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import lmdb\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def check_image_is_valid(image_bin):\n",
    "    if image_bin is None:\n",
    "        return False\n",
    "    img = cv2.imdecode(np.frombuffer(image_bin, np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    return img is not None and img.size > 0\n",
    "\n",
    "def write_cache(env, cache):\n",
    "    with env.begin(write=True) as txn:\n",
    "        for k, v in cache.items():\n",
    "            txn.put(k.encode(), v)\n",
    "\n",
    "def list_all_images(root_dir, exts={'.png', '.jpg', '.jpeg'}):\n",
    "    img_paths = []\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for f in files:\n",
    "            if os.path.splitext(f)[1].lower() in exts:\n",
    "                img_paths.append(os.path.join(root, f))\n",
    "    return img_paths\n",
    "\n",
    "def create_lmdb(output_path, img_root, csv_path, csv_key=\"filepath\", csv_label=\"label\"):\n",
    "    print(f\"Reading truth file: {csv_path}\")\n",
    "\n",
    "    # Load CSV into dictionary\n",
    "    truth = {}\n",
    "    with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            key = row[csv_key].replace(\"\\\\\", \"/\")  # normalize slashes\n",
    "            truth[key] = row[csv_label]\n",
    "\n",
    "    print(f\"Loaded {len(truth)} label entries from CSV\")\n",
    "\n",
    "    print(f\"Scanning for images under: {img_root}\")\n",
    "    all_imgs = list_all_images(img_root)\n",
    "\n",
    "    print(f\"Found {len(all_imgs)} total image files\")\n",
    "\n",
    "    env = lmdb.open(output_path, map_size=1099511627776)\n",
    "    cache = {}\n",
    "    cnt = 1\n",
    "\n",
    "    for img_path in tqdm(all_imgs, desc=\"Creating LMDB\"):\n",
    "        rel = os.path.relpath(img_path, img_root).replace(\"\\\\\", \"/\")\n",
    "\n",
    "        if rel not in truth:\n",
    "            print(f\"[WARN] No label found for: {rel}\")\n",
    "            continue\n",
    "\n",
    "        label = truth[rel]\n",
    "        with open(img_path, \"rb\") as f:\n",
    "            img_bin = f.read()\n",
    "\n",
    "        if not check_image_is_valid(img_bin):\n",
    "            print(f\"[SKIP] Invalid image: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        img_key = f\"image-{cnt:09d}\"\n",
    "        label_key = f\"label-{cnt:09d}\"\n",
    "\n",
    "        cache[img_key] = img_bin\n",
    "        cache[label_key] = label.encode(\"utf-8\")\n",
    "\n",
    "        if cnt % 1000 == 0:\n",
    "            write_cache(env, cache)\n",
    "            cache.clear()\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "    cache[\"num-samples\"] = str(cnt - 1).encode()\n",
    "    write_cache(env, cache)\n",
    "    env.close()\n",
    "\n",
    "    print(f\"\\n✅ LMDB successfully created with {cnt - 1} samples at: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 4:\n",
    "        print(\"Usage: python create_lmdb_nested_csv.py <output_lmdb_path> <image_root_folder> <truth.csv>\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    output = sys.argv[1]\n",
    "    image_root = sys.argv[2]\n",
    "    csv_file = sys.argv[3]\n",
    "\n",
    "    create_lmdb(output, image_root, csv_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocrenv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
