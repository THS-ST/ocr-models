{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55022756",
   "metadata": {},
   "source": [
    "# TrOCR â€” Quick Test Notebook \n",
    "\n",
    "This notebook lets you:\n",
    "- Load a **local** TrOCR checkpoint (e.g., `./runs/trocr/epoch_1`)\n",
    "- Run a **single-image** prediction\n",
    "- Run a **mini evaluation** (CER/WER) on a CSV split\n",
    "\n",
    "> **Run this notebook from *inside* your `TrOCR/` folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6975ebbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== 0) Paths you can edit ====\n",
    "CKPT_PATH = \"./runs/trocr/epoch_1\"   # checkpoint folder saved by your trainer\n",
    "IMG_PATH  = \"../data/image_splits/validation_set_splits/V06/page_1/line_20.png\"  # any existing image\n",
    "VAL_CSV   = \"./val_tiny_exist.csv\"   # CSV with columns: image_path, transcription\n",
    "\n",
    "# Decoding settings\n",
    "DECODE_MAX_NEW_TOKENS = 64\n",
    "DECODE_NUM_BEAMS = 5\n",
    "DECODE_DO_SAMPLE = False\n",
    "\n",
    "# Helpful env flags (optional)\n",
    "import os\n",
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e71087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "# ==== 1) Imports & device ====\n",
    "import os, torch\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "def pick_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    has_mps = getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available()\n",
    "    if has_mps:\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = pick_device()\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f265a14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded processor & model from: ./runs/trocr/epoch_1\n"
     ]
    }
   ],
   "source": [
    "# ==== 2) Load processor & model from LOCAL checkpoint ====\n",
    "assert os.path.isdir(CKPT_PATH), f\"Checkpoint dir not found: {CKPT_PATH}\"\n",
    "\n",
    "# Load locally to avoid Hub lookups\n",
    "processor = TrOCRProcessor.from_pretrained(CKPT_PATH, use_fast=False, local_files_only=True)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(CKPT_PATH, local_files_only=True).to(device).eval()\n",
    "\n",
    "# Guard config for stage1-like checkpoints\n",
    "if getattr(model.config, \"decoder_start_token_id\", None) is None:\n",
    "    model.config.decoder_start_token_id = processor.tokenizer.bos_token_id\n",
    "if getattr(model.config, \"pad_token_id\", None) is None:\n",
    "    model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "\n",
    "# Keep label length modest (matches memory-friendly training advice)\n",
    "try:\n",
    "    processor.tokenizer.model_max_length = max(processor.tokenizer.model_max_length, 128)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Loaded processor & model from:\", CKPT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd2c41b",
   "metadata": {},
   "source": [
    "## Single-image prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26e497ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED: # 30\n"
     ]
    }
   ],
   "source": [
    "# ==== 3) Predict on one image ====\n",
    "assert os.path.isfile(IMG_PATH), f\"Image not found: {IMG_PATH}\"\n",
    "img = Image.open(IMG_PATH).convert(\"RGB\")\n",
    "\n",
    "inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=DECODE_MAX_NEW_TOKENS,\n",
    "        num_beams=DECODE_NUM_BEAMS,\n",
    "        do_sample=DECODE_DO_SAMPLE,\n",
    "    )\n",
    "pred = processor.batch_decode(ids, skip_special_tokens=True)[0]\n",
    "print(\"PRED:\", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957b7ac",
   "metadata": {},
   "source": [
    "## Mini evaluation (CER/WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9503a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 37\n",
      "CER: 0.8782816229116945\n",
      "WER: 1.0158730158730158\n"
     ]
    }
   ],
   "source": [
    "# ==== 4) Evaluate on a CSV (tiny val) ====\n",
    "\n",
    "import pandas as pd\n",
    "from jiwer import cer, wer\n",
    "\n",
    "assert os.path.isfile(VAL_CSV), f\"CSV not found: {VAL_CSV}\"\n",
    "df = pd.read_csv(VAL_CSV)\n",
    "assert \"image_path\" in df.columns and \"transcription\" in df.columns, \"CSV must have columns: image_path, transcription\"\n",
    "\n",
    "gts, preds = [], []\n",
    "for _, r in df.iterrows():\n",
    "    p = r[\"image_path\"]\n",
    " \n",
    "    full = p if os.path.isabs(p) else os.path.join(\"..\", p)\n",
    "    if not os.path.isfile(full):\n",
    "        # skip missing rows\n",
    "        continue\n",
    "    img = Image.open(full).convert(\"RGB\")\n",
    "    inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=DECODE_MAX_NEW_TOKENS,\n",
    "            num_beams=DECODE_NUM_BEAMS,\n",
    "            do_sample=DECODE_DO_SAMPLE,\n",
    "        )\n",
    "    preds.append(processor.batch_decode(ids, skip_special_tokens=True)[0])\n",
    "    gts.append(str(r[\"transcription\"]))\n",
    "\n",
    "print(\"samples:\", len(preds))\n",
    "if len(preds):\n",
    "    print(\"CER:\", cer(gts, preds))\n",
    "    print(\"WER:\", wer(gts, preds))\n",
    "else:\n",
    "    print(\"No valid samples found (check VAL_CSV paths and that files exist)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "132edce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 16\n",
      "CER: 0.8065693430656934\n",
      "WER: 0.9615384615384616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Multivitamin', ': tablet #'),\n",
       " ('mefenamic acid 500mg/capsule', ': tablet x'),\n",
       " ('S:', '#'),\n",
       " ('Label: 1 tablet after breakfast', ': tablet x'),\n",
       " ('Telmisartan #200', 'Bioene')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from jiwer import cer, wer\n",
    "\n",
    "CKPT = \"./runs/overfit16_strict/epoch_15\"        # change to your best epoch\n",
    "CSV  = \"./overfit16.csv\"\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available()\n",
    "          else \"mps\" if getattr(torch.backends,\"mps\",None) and torch.backends.mps.is_available()\n",
    "          else \"cpu\")\n",
    "proc  = TrOCRProcessor.from_pretrained(CKPT, use_fast=False, local_files_only=True)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(CKPT, local_files_only=True).to(device).eval()\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "preds, gts = [], []\n",
    "for _, r in df.iterrows():\n",
    "    full = os.path.join(\"..\", r[\"image_path\"])  # CSV is relative to repo root\n",
    "    if not os.path.isfile(full): continue\n",
    "    img = Image.open(full).convert(\"RGB\")\n",
    "    inp = proc(images=img, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        ids = model.generate(\n",
    "            **inp,\n",
    "            num_beams=8, do_sample=False, max_new_tokens=64,\n",
    "            no_repeat_ngram_size=3, repetition_penalty=1.2,\n",
    "            length_penalty=0.8, early_stopping=True,\n",
    "        )\n",
    "    preds.append(proc.batch_decode(ids, skip_special_tokens=True)[0])\n",
    "    gts.append(str(r[\"transcription\"]))\n",
    "\n",
    "print(\"samples:\", len(preds))\n",
    "print(\"CER:\", cer(gts, preds))\n",
    "print(\"WER:\", wer(gts, preds))\n",
    "list(zip(gts, preds))[:5]  # peek first 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6097fe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED: Daily\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import torch, os, re\n",
    "\n",
    "ckpt = \"./runs/overfit1_strict/epoch_60\"  # your checkpoint\n",
    "img  = \"../data/image_splits/validation_set_splits/V06/page_1/line_7.png\"  # your test image\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available()\n",
    "          else \"mps\" if getattr(torch.backends,\"mps\",None) and torch.backends.mps.is_available()\n",
    "          else \"cpu\")\n",
    "\n",
    "proc  = TrOCRProcessor.from_pretrained(ckpt, use_fast=False, local_files_only=True)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(ckpt, local_files_only=True).to(device).eval()\n",
    "\n",
    "# Make sure config has proper ids (safety)\n",
    "if getattr(model.config, \"decoder_start_token_id\", None) is None:\n",
    "    model.config.decoder_start_token_id = proc.tokenizer.bos_token_id\n",
    "if getattr(model.config, \"pad_token_id\", None) is None:\n",
    "    model.config.pad_token_id = proc.tokenizer.pad_token_id\n",
    "eos_id = proc.tokenizer.eos_token_id\n",
    "\n",
    "im  = Image.open(img).convert(\"RGB\")\n",
    "inp = proc(images=im, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Use beam search + anti-repetition\n",
    "ids = model.generate(\n",
    "    **inp,\n",
    "    num_beams=8,                 # enables length_penalty\n",
    "    do_sample=False,\n",
    "    max_new_tokens=16,           # short since GT is \"Daily\"\n",
    "    no_repeat_ngram_size=3,      # block short repeats\n",
    "    repetition_penalty=1.3,      # discourage token reuse\n",
    "    length_penalty=0.8,          # used only with beams\n",
    "    eos_token_id=eos_id,         # encourage stopping\n",
    "    pad_token_id=model.config.pad_token_id,\n",
    ")\n",
    "\n",
    "pred = proc.batch_decode(ids, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "# Optional tiny post-process: collapse immediate word duplicates\n",
    "pred = re.sub(r\"\\b(\\w+)(\\s+\\1\\b)+\", r\"\\1\", pred)\n",
    "\n",
    "print(\"PRED:\", pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69615c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "python - <<'PY'\n",
    "import os, torch, pandas as pd\n",
    "from PIL import Image\n",
    "from jiwer import cer, wer\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "CKPT=\"TrOCR/runs/hw_refine_lr3e6/epoch_3\"\n",
    "CSV =\"TrOCR/val.csv\"; BASE=\".\"\n",
    "\n",
    "proc  = TrOCRProcessor.from_pretrained(CKPT, use_fast=False, local_files_only=True)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(CKPT, local_files_only=True).eval()\n",
    "\n",
    "preds,gts=[],[]\n",
    "df = pd.read_csv(CSV)\n",
    "for _, r in df.iterrows():\n",
    "    p = r[\"image_path\"]; p = p if os.path.isabs(p) else os.path.join(BASE,p)\n",
    "    if not os.path.isfile(p): continue\n",
    "    im = Image.open(p).convert(\"RGB\")\n",
    "    inp = proc(images=im, return_tensors=\"pt\")\n",
    "    ids = model.generate(**inp, num_beams=10, do_sample=False, max_new_tokens=64,\n",
    "                         no_repeat_ngram_size=4, repetition_penalty=1.5, length_penalty=0.8)\n",
    "    preds.append(proc.batch_decode(ids, skip_special_tokens=True)[0])\n",
    "    gts.append(str(r[\"transcription\"]))\n",
    "print(\"samples:\",len(preds))\n",
    "print(\"CER/WER:\", cer(gts,preds), wer(gts,preds))\n",
    "for i,(gt,pr) in enumerate(list(zip(gts,preds))[:20]):\n",
    "    print(f\"\\n[{i}] GT: {gt}\\n     PR: {pr}\")\n",
    "PY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
