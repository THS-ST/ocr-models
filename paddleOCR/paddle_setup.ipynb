{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "DaDVwLifXCk6",
      "metadata": {
        "id": "DaDVwLifXCk6"
      },
      "source": [
        "## OCR Training (PaddleOCR)\n",
        "\n",
        "(setup for files only)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "STmL0iBUXCk_",
      "metadata": {
        "id": "STmL0iBUXCk_"
      },
      "source": [
        "### 1. Install Dependencies & Clone PaddleOCR Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "O9ssvwZ2XClA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9ssvwZ2XClA",
        "outputId": "0cf5b4e4-eb33-4e55-d7d1-664622b2b155"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "! was unexpected at this time.\n"
          ]
        }
      ],
      "source": [
        "!pip install paddlepaddle-gpu -q\n",
        "!pip install paddleocr pyyaml -q\n",
        "!pip install pandas -q\n",
        "!pip install numpy -q\n",
        "!pip install scikit-learn -q\n",
        "!pip install jiwer -q\n",
        "\n",
        "# Clone the repo if not already cloned\n",
        "!if [ ! -d \"PaddleOCR\" ]; then git clone https://github.com/PaddlePaddle/PaddleOCR.git; fi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3e742873",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e742873",
        "outputId": "ebea8ab0-5a02-48c2-9686-780f6760b35f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install the repo's requirements\n",
        "!pip install -r PaddleOCR/requirements.txt -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "veya4AHGXClC",
      "metadata": {
        "id": "veya4AHGXClC"
      },
      "source": [
        "### 2. Define Paths and Load DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QlFu6G9BXClC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlFu6G9BXClC",
        "outputId": "17602d21-a962-46c8-f6f1-f84a7687f610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 9 total samples from ground_truth_lines.csv.\n",
            "Split into 8 training samples and 1 testing samples.\n",
            "\n",
            "Sample image path from CSV:\n",
            "splits/data_1/line_1.png\n",
            "\n",
            "Training DataFrame head:\n",
            "                  image_path  \\\n",
            "1   splits/data_1/line_1.png   \n",
            "5   splits/data_1/line_6.png   \n",
            "0   splits/data_1/line_0.png   \n",
            "8   splits/data_1/line_9.png   \n",
            "2  splits/data_1/line_10.png   \n",
            "\n",
            "                                       transcription  \n",
            "1                 Sig: 1 tab once a morning for itch  \n",
            "5                                                 #5  \n",
            "0                             Loratadine 10mg/tab #5  \n",
            "8            3. Clobetasol Propionate 0.05% cream #1  \n",
            "2  Sig: Ipahid nang manipis sa mga apektadong bahagi  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import yaml # For creating the config file\n",
        "from jiwer import wer, cer # For evaluation\n",
        "from sklearn.model_selection import train_test_split # To split our data\n",
        "\n",
        "def _wer(gt, pred):\n",
        "    return wer(gt, pred)\n",
        "\n",
        "def _cer(gt, pred):\n",
        "    return cer(gt, pred)\n",
        "\n",
        "# --- PATHS TO SAVE MODELS ---\n",
        "PADDLE_DATA_DIR = Path(\"./paddle_training_data\")\n",
        "PADDLE_DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- FILE PATHS ---\n",
        "GT_CSV = Path(\"./ground_truth_lines.csv\") # Main ground truth file\n",
        "\n",
        "TRAIN_LABEL_FILE = PADDLE_DATA_DIR / \"train_label.txt\"\n",
        "TEST_LABEL_FILE = PADDLE_DATA_DIR / \"test_label.txt\"\n",
        "DICT_FILE = PADDLE_DATA_DIR / \"dict.txt\"\n",
        "\n",
        "# --- LOAD DATAFRAME --- (tba: remove train/test and use folders instead for full dataset training)\n",
        "try:\n",
        "    gt_df = pd.read_csv(GT_CSV)\n",
        "    print(f\"Loaded {len(gt_df)} total samples from {GT_CSV}.\")\n",
        "\n",
        "    # Split the data into training and testing sets (e.g., 90% train, 10% test)\n",
        "    train_df, test_df = train_test_split(gt_df, test_size=0.1, random_state=42)\n",
        "\n",
        "    print(f\"Split into {len(train_df)} training samples and {len(test_df)} testing samples.\")\n",
        "\n",
        "    # Check if 'image_path' and 'transcription' columns exist\n",
        "    if 'image_path' not in train_df.columns or 'transcription' not in train_df.columns:\n",
        "        raise ValueError(\"CSV must contain 'image_path' and 'transcription' columns.\")\n",
        "\n",
        "    print(\"\\nSample image path from CSV:\")\n",
        "    print(train_df.iloc[0]['image_path'])\n",
        "    print(\"\\nTraining DataFrame head:\")\n",
        "    print(train_df.head())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Could not find {GT_CSV}.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MRgUZwh0XClD",
      "metadata": {
        "id": "MRgUZwh0XClD"
      },
      "source": [
        "### 3. Prepare PaddleOCR Data Files\n",
        "\n",
        "Paddle's training script requires two types of files:\n",
        "1.  **Label Files (`.txt`):** A text file where each line is `image_path\\ttranscription`.\n",
        "2.  **Dictionary File (`dict.txt`):** A vocabulary file listing every unique character in your training set, one character per line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HevEwKDNXClE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HevEwKDNXClE",
        "outputId": "bf0338b9-604f-4f92-a55b-52e799a245bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing paddle_training_data\\train_label.txt...\n",
            "Writing paddle_training_data\\test_label.txt...\n",
            "Generating paddle_training_data\\dict.txt...\n",
            "Dictionary created with 38 unique characters.\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Generate Label Files ---\n",
        "print(f\"Writing {TRAIN_LABEL_FILE}...\")\n",
        "with open(TRAIN_LABEL_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in train_df.iterrows():\n",
        "        f.write(f\"{str(row['image_path']).replace('//', '/')}\\t{row['transcription']}\\n\")\n",
        "\n",
        "print(f\"Writing {TEST_LABEL_FILE}...\")\n",
        "with open(TEST_LABEL_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in test_df.iterrows():\n",
        "        f.write(f\"{str(row['image_path']).replace('//', '/')}\\t{row['transcription']}\\n\")\n",
        "\n",
        "# --- 2. Generate Dictionary (Vocabulary) File ---\n",
        "print(f\"Generating {DICT_FILE}...\")\n",
        "all_text = \"\".join(gt_df[\"transcription\"].tolist())\n",
        "unique_chars = sorted(list(set(all_text)))\n",
        "\n",
        "with open(DICT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    for char in unique_chars:\n",
        "        f.write(f\"{char}\\n\")\n",
        "\n",
        "print(f\"Dictionary created with {len(unique_chars)} unique characters.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SIjJHSvLXClE",
      "metadata": {
        "id": "SIjJHSvLXClE"
      },
      "source": [
        "### Test: Using pre-trained Model as baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cq75dw23XClF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq75dw23XClF",
        "outputId": "8c3c1b44-e174-4c90-9e33-ba960317f011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-trained model already exists at en_PP-OCRv4_rec_train\n"
          ]
        }
      ],
      "source": [
        "PRETRAINED_MODEL_URL = \"https://paddleocr.bj.bcebos.com/PP-OCRv4/english/en_PP-OCRv4_rec_train.tar\"\n",
        "PRETRAINED_MODEL_PATH = Path(\"./en_PP-OCRv4_rec_train\")\n",
        "\n",
        "if not PRETRAINED_MODEL_PATH.exists():\n",
        "    print(\"Extracting pre-trained model...\")\n",
        "    !tar -xf en_PP-OCRv4_rec_train.tar\n",
        "    print(f\"Model downloaded and extracted to {PRETRAINED_MODEL_PATH}\")\n",
        "else:\n",
        "    print(f\"Pre-trained model already exists at {PRETRAINED_MODEL_PATH}\")\n",
        "\n",
        "pretrained_model_path = os.path.join(base_dir, PRETRAINED_MODEL_PATH, \"best_accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qE9qDVYwXClF",
      "metadata": {
        "id": "qE9qDVYwXClF"
      },
      "source": [
        "### 4. Create Custom Training Configuration (`.yml`)\n",
        "\n",
        "Paddle is controlled by a YAML file. We are creating a new file, `my_custom_config.yml`, that inherits from the base config but overrides the key parameters to point to our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29beb851",
      "metadata": {},
      "outputs": [],
      "source": [
        "# absolute paths because the training script runs from within the 'PaddleOCR' directory\n",
        "base_dir = os.path.abspath(os.getcwd())\n",
        "dict_path = os.path.join(base_dir, DICT_FILE)\n",
        "train_label_path = os.path.join(base_dir, TRAIN_LABEL_FILE)\n",
        "test_label_path = os.path.join(base_dir, TEST_LABEL_FILE)\n",
        "save_model_dir = os.path.join(base_dir, \"output/my_paddle_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "962d79b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_label_path = train_label_path.replace('\\\\', '/')\n",
        "test_label_path = test_label_path.replace('\\\\', '/')\n",
        "\n",
        "use_gpu = \"true\"\n",
        "epochs = 100\n",
        "images_root = \"./\"\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "wrkUVFFWXClG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrkUVFFWXClG",
        "outputId": "65d6e9c9-503a-48f8-82d9-40fdb55b730c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Custom config file saved to PaddleOCR\\configs\\rec\\my_custom_config.yml\n"
          ]
        }
      ],
      "source": [
        "# Define the custom config content\n",
        "config_content = f\"\"\"\n",
        "Global:\n",
        "  debug: false\n",
        "  use_gpu: {use_gpu}\n",
        "  epoch_num: {epochs}\n",
        "  distributed: false\n",
        "  save_model_dir: {save_model_dir}\n",
        "  save_epoch_step: 10\n",
        "  print_batch_step: 10\n",
        "  eval_batch_step: [0, 1000] # Evaluate every 1000 steps, and at the start (step 0)\n",
        "  save_best: \"acc\" \n",
        "  cal_metric_during_train: true\n",
        "  pretrained_model: \"\"\n",
        "  checkpoints: \"\"\n",
        "  save_inference_dir: {save_model_dir}/inference\n",
        "  use_visualdl: true\n",
        "  infer_img: \"\"\n",
        "  character_dict_path: {dict_path}\n",
        "  max_text_length: 50\n",
        "  use_space_char: true\n",
        "  infer_mode: false\n",
        "  log_smooth_window: 20\n",
        "  save_res_path: {save_model_dir}/train_results.txt\n",
        "Optimizer:\n",
        "  name: Adam\n",
        "  lr:\n",
        "    name: Cosine\n",
        "    learning_rate: 0.001\n",
        "  regularizer:\n",
        "    name: L2\n",
        "    factor: 0.00001\n",
        "Architecture:\n",
        "  model_type: rec\n",
        "  algorithm: CRNN\n",
        "  Transform:\n",
        "  Backbone:\n",
        "    name: ResNet\n",
        "    layers: 34\n",
        "  Neck:\n",
        "    name: SequenceEncoder\n",
        "    encoder_type: rnn\n",
        "    hidden_size: 256\n",
        "  Head:\n",
        "    name: CTCHead\n",
        "    fc_decay: 0.00001\n",
        "Loss:\n",
        "  name: CTCLoss\n",
        "PostProcess:\n",
        "  name: CTCLabelDecode\n",
        "  character_dict_path: {dict_path}\n",
        "  use_space_char: true\n",
        "Metric:\n",
        "  name: RecMetric\n",
        "  main_indicator: acc\n",
        "  character_dict_path: {dict_path}\n",
        "  use_space_char: true\n",
        "Train:\n",
        "  dataset:\n",
        "    name: SimpleDataSet\n",
        "    data_dir: {images_root}\n",
        "    label_file_list: [\"{train_label_path}\"]\n",
        "    transforms:\n",
        "      - DecodeImage: {{img_mode: BGR, channel_first: false}}\n",
        "      - RecResizeImg: {{image_shape: [3, 32, 320]}}\n",
        "      - CTCLabelEncode: {{}}\n",
        "      - KeepKeys: {{keep_keys: [\"image\", \"label\", \"length\"]}}\n",
        "  loader:\n",
        "    shuffle: true\n",
        "    batch_size_per_card: {batch_size}\n",
        "    drop_last: true\n",
        "    num_workers: 4\n",
        "Eval:\n",
        "  dataset:\n",
        "    name: SimpleDataSet\n",
        "    data_dir: {images_root}\n",
        "    label_file_list: [\"{train_label_path}\"]\n",
        "    transforms:\n",
        "      - DecodeImage: {{img_mode: BGR, channel_first: false}}\n",
        "      - RecResizeImg: {{image_shape: [3, 32, 320]}}\n",
        "      - CTCLabelEncode: {{}}\n",
        "      - KeepKeys: {{keep_keys: [\"image\", \"label\", \"length\"]}}\n",
        "  loader:\n",
        "    shuffle: false\n",
        "    batch_size_per_card: {batch_size}\n",
        "    drop_last: false\n",
        "    num_workers: 2\n",
        "\"\"\"\n",
        "\n",
        "# Save the config file inside the PaddleOCR directory\n",
        "CONFIG_FILE_PATH = Path(\"PaddleOCR/configs/rec/my_custom_config.yml\")\n",
        "with open(CONFIG_FILE_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(config_content)\n",
        "\n",
        "print(f\"Custom config file saved to {CONFIG_FILE_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.10)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
